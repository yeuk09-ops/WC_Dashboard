import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { loadAICache, updateAICachePartial } from '@/lib/ai-cache';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    const { data, quarter, forceRegenerate } = await request.json();

    if (!quarter) {
      return NextResponse.json(
        { success: false, error: 'ë¶„ê¸° ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    // ìºì‹œ í™•ì¸ (ê°•ì œ ì¬ìƒì„±ì´ ì•„ë‹Œ ê²½ìš°)
    if (!forceRegenerate) {
      const cache = loadAICache(quarter);
      if (cache?.actionPlan) {
        console.log(`âœ… AI ì•¡ì…˜í”Œëœ ìºì‹œ ì‚¬ìš©: ${quarter}`);
        return NextResponse.json({
          success: true,
          actionItems: cache.actionPlan,
          cached: true,
          generatedAt: cache.generatedAt,
        });
      }
    }

    if (!openai.apiKey) {
      return NextResponse.json(
        { success: false, error: 'OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.' },
        { status: 500 }
      );
    }

    console.log(`ğŸ¤– AI ì•¡ì…˜í”Œëœ ìƒì„± ì¤‘: ${quarter}`);

    const prompt = `ë‹¹ì‹ ì€ F&F ê·¸ë£¹ì˜ ì¬ë¬´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìš´ì „ìë³¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìš°ì„ ìˆœìœ„ë³„ ì•¡ì…˜í”Œëœì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

ë°ì´í„°: ${JSON.stringify(data)}

ë‹¤ìŒ í˜•ì‹ì˜ JSON ë°°ì—´ì„ ë°˜í™˜í•´ì£¼ì„¸ìš” (5-7ê°œ í•­ëª©):
[
  {
    "priority": "HIGH" | "MEDIUM" | "LOW",
    "label": "ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ì¬ê³ , ì±„ê¶Œ, ì±„ë¬´, ìš´ì „ìë³¸ ë“±)",
    "issue": "êµ¬ì²´ì ì¸ ì´ìŠˆ ì„¤ëª… (ìˆ˜ì¹˜ í¬í•¨)",
    "action": "ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì•¡ì…˜",
    "target": "ëª©í‘œ ìˆ˜ì¹˜ ë˜ëŠ” KPI",
    "responsible": "ë‹´ë‹¹ ë¶€ì„œ/ë²•ì¸"
  }
]

ìš°ì„ ìˆœìœ„ íŒë‹¨ ê¸°ì¤€:
- HIGH: ì „ë…„ ëŒ€ë¹„ 20% ì´ìƒ ì•…í™”, CCC 100ì¼ ì´ˆê³¼, ì¦‰ê°ì ì¸ í˜„ê¸ˆíë¦„ ë¦¬ìŠ¤í¬
- MEDIUM: ì „ë…„ ëŒ€ë¹„ 10-20% ì•…í™”, ë¶„ê¸° ë‚´ ê°œì„  í•„ìš”
- LOW: ì•ˆì •ì ì´ë‚˜ ëª¨ë‹ˆí„°ë§ í•„ìš”

ì£¼ìš” ë¶„ì„ í¬ì¸íŠ¸:
1. ê° ë²•ì¸ë³„ ìš´ì „ìë³¸ ì¦ê°ë¥  (YoY)
2. CCC(í˜„ê¸ˆì „í™˜ì£¼ê¸°) ë³€í™” ë° ëª©í‘œ ëŒ€ë¹„ ê´´ë¦¬
3. DSO, DIO, DPO ê° ì§€í‘œì˜ ì´ìƒì¹˜
4. ì¬ê³ , ë§¤ì¶œì±„ê¶Œ, ë§¤ì…ì±„ë¬´ì˜ ê¸‰ê²©í•œ ë³€í™”
5. ë²•ì¸ë³„ íŠ¹ì´ì‚¬í•­ ë° ë¦¬ìŠ¤í¬

**ì¤‘ìš”**: ì˜¤ì§ JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.`;

    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.7,
      max_tokens: 1500,
    });

    const responseText = completion.choices[0].message.content?.trim() || '[]';
    
    // JSON ì¶”ì¶œ (ì½”ë“œ ë¸”ë¡ì´ ìˆì„ ê²½ìš° ì œê±°)
    let jsonText = responseText;
    if (responseText.includes('```json')) {
      jsonText = responseText.split('```json')[1].split('```')[0].trim();
    } else if (responseText.includes('```')) {
      jsonText = responseText.split('```')[1].split('```')[0].trim();
    }
    
    const actionItems = JSON.parse(jsonText);

    // ìºì‹œì— ì €ì¥
    updateAICachePartial(quarter, 'actionPlan', actionItems);
    console.log(`âœ… AI ì•¡ì…˜í”Œëœ ìºì‹œ ì €ì¥: ${quarter}`);

    return NextResponse.json({
      success: true,
      actionItems,
      cached: false,
      generatedAt: new Date().toISOString(),
    });
  } catch (error) {
    console.error('AI ì•¡ì…˜í”Œëœ ìƒì„± ì˜¤ë¥˜:', error);
    return NextResponse.json(
      { success: false, error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    );
  }
}
